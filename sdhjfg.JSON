[
  {
    "id": "da-001",
    "area": "Retail Demand Forecasting",
    "short_description": "Predict short-term product demand at store or SKU level to reduce stockouts and overstock.",
    "typical_use_cases": ["Inventory optimization", "Promotion planning", "Reorder alerts"],
    "sample_data_sources": ["POS transaction logs", "promotions calendar", "weather", "holidays"],
    "required_skills": ["time series forecasting", "feature engineering", "evaluation (MAPE)"],
    "difficulty": "medium",
    "potential_impact": "lower carrying costs, improved availability",
    "starter_project": "Forecast daily SKU sales for 10 stores using Prophet or LSTM"
  },
  {
    "id": "da-002",
    "area": "Customer Churn Prediction",
    "short_description": "Identify customers likely to stop using a product/service so retention actions can be targeted.",
    "typical_use_cases": ["Targeted retention campaigns", "Customer lifetime value improvement"],
    "sample_data_sources": ["CRM events", "usage logs", "billing history", "support tickets"],
    "required_skills": ["classification", "imbalanced data handling", "explainability (SHAP)"],
    "difficulty": "medium",
    "potential_impact": "reduced churn, higher revenue per customer",
    "starter_project": "Build a churn classifier and deploy a dashboard of top risk factors"
  },
  {
    "id": "da-003",
    "area": "Anomaly Detection for Logs & Metrics",
    "short_description": "Detect unusual behavior in system logs or metrics to speed incident response.",
    "typical_use_cases": ["Alerting", "Root-cause hints", "Capacity planning"],
    "sample_data_sources": ["application logs", "server metrics (CPU, latency)", "traces"],
    "required_skills": ["unsupervised/supervised anomaly detection", "time-series smoothing"],
    "difficulty": "medium",
    "potential_impact": "faster incident detection, reduced downtime",
    "starter_project": "Unsupervised anomaly detector using isolation forest on metric windows"
  },
  {
    "id": "da-004",
    "area": "Geospatial Analysis for Site Selection",
    "short_description": "Use spatial data to recommend optimal locations for retail, logistics, or services.",
    "typical_use_cases": ["New store placement", "delivery hub planning", "service coverage analysis"],
    "sample_data_sources": ["points of interest", "census data", "traffic/footfall", "satellite imagery"],
    "required_skills": ["GIS tools (GeoPandas)", "spatial joins", "heatmaps"],
    "difficulty": "medium",
    "potential_impact": "better site ROI, improved accessibility",
    "starter_project": "Create a heatmap of underserved neighborhoods and rank candidate locations"
  },
  {
    "id": "da-005",
    "area": "Healthcare Predictive Models",
    "short_description": "Predict patient outcomes (readmission, complications) to prioritize interventions.",
    "typical_use_cases": ["Readmission risk scoring", "triage prioritization", "resource allocation"],
    "sample_data_sources": ["EHR records", "lab tests", "medication history", "demographics"],
    "required_skills": ["risk modeling", "privacy/PHI handling", "clinical evaluation metrics"],
    "difficulty": "high",
    "potential_impact": "improved patient outcomes, cost reduction",
    "starter_project": "Predict 30-day readmission risk with explainable XGBoost"
  },
  {
    "id": "da-006",
    "area": "Recommendation Systems",
    "short_description": "Provide personalized item or content recommendations to increase engagement.",
    "typical_use_cases": ["Product recommendations", "content feeds", "cross-sell"],
    "sample_data_sources": ["user-item interactions", "item metadata", "session events"],
    "required_skills": ["collaborative filtering", "matrix factorization", "ranking metrics"],
    "difficulty": "medium",
    "potential_impact": "higher conversion, average order value growth",
    "starter_project": "Build a hybrid recommender that mixes popularity and matrix factorization"
  },
  {
    "id": "da-007",
    "area": "NLP for Customer Feedback",
    "short_description": "Extract themes, sentiment, and intent from reviews, tickets, or surveys.",
    "typical_use_cases": ["CSAT analysis", "feature request aggregation", "automated tagging"],
    "sample_data_sources": ["support tickets", "product reviews", "survey responses"],
    "required_skills": ["text preprocessing", "topic modeling", "sentiment analysis", "transformers"],
    "difficulty": "low",
    "potential_impact": "faster insights, prioritized product improvements",
    "starter_project": "Run topic modeling and sentiment over 10k reviews and summarize top issues"
  },
  {
    "id": "da-008",
    "area": "Image Analytics for Quality Control",
    "short_description": "Automated visual inspection to detect defects in manufacturing or production lines.",
    "typical_use_cases": ["defect detection", "classification of part types", "process monitoring"],
    "sample_data_sources": ["camera images", "microscope images", "inspection logs"],
    "required_skills": ["computer vision (CNNs)", "data augmentation", "edge deployment"],
    "difficulty": "high",
    "potential_impact": "reduced scrap, improved yield",
    "starter_project": "Train a CNN to classify defective vs. non-defective parts with transfer learning"
  },
  {
    "id": "da-009",
    "area": "Energy Consumption Optimization",
    "short_description": "Model and reduce energy use across buildings or fleets using sensor and schedule data.",
    "typical_use_cases": ["HVAC scheduling", "anomaly detection in meters", "efficiency benchmarking"],
    "sample_data_sources": ["smart meter readings", "weather", "occupancy sensors"],
    "required_skills": ["time series, optimization, domain knowledge"],
    "difficulty": "medium",
    "potential_impact": "cost savings, emissions reduction",
    "starter_project": "Forecast hourly building load and recommend setpoint changes to reduce peak usage"
  },
  {
    "id": "da-010",
    "area": "Financial Fraud Detection",
    "short_description": "Detect suspicious transactions or patterns to stop fraud in real time.",
    "typical_use_cases": ["transaction monitoring", "account takeover detection", "AML alerts"],
    "sample_data_sources": ["transaction logs", "device fingerprinting", "geolocation"],
    "required_skills": ["streaming detection, feature creation, precision/recall tuning"],
    "difficulty": "high",
    "potential_impact": "loss prevention, regulatory compliance",
    "starter_project": "Prototype a scoring pipeline with streaming features and a supervised model"
  },
  {
    "id": "da-011",
    "area": "Public Policy & Social Data Analysis",
    "short_description": "Analyze demographic and administrative data to support policy decisions and services.",
    "typical_use_cases": ["impact assessments", "resource allocation", "program evaluation"],
    "sample_data_sources": ["census, open government datasets, surveys, administrative records"],
    "required_skills": ["causal inference basics, visualization, data cleaning"],
    "difficulty": "medium",
    "potential_impact": "better-targeted services, measurable social outcomes",
    "starter_project": "Evaluate program uptake across regions and visualize disparities"
  },
  {
    "id": "da-012",
    "area": "Synthetic Data & Privacy-preserving Models",
    "short_description": "Generate synthetic datasets or apply differential privacy to enable safe data sharing.",
    "typical_use_cases": ["data sharing for ML, compliance-friendly analytics, model training"],
    "sample_data_sources": ["sensitive records (anonymized), simulated data generators"],
    "required_skills": ["GANs/flow models, differential privacy, evaluation of utility vs. privacy"],
    "difficulty": "high",
    "potential_impact": "unlock data for teams while protecting privacy",
    "starter_project": "Create a small synthetic tabular dataset and measure downstream model performance loss"
  }
]
